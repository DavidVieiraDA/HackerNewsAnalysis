{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Data Analysis Project\n",
    "\n",
    "## By: David Vieira\n",
    "\n",
    "In this project we are agoing to work with a dataset provided by the famous online website Hacker News, which was create by the startup incubator Y Combinator. This site works with user submitted posts that are voted and commented getting recognition to the point that popular post can get a bunch of visitors.\n",
    "\n",
    "The data set that is going to be used can be found [Here](https://www.kaggle.com/hacker-news/hacker-news-posts). This data set has a particularity, because it was reduced from about 300,000 rows to about 20,000 by removing posts that were not commented at all and then randomnly taking a sample from the remaining ones.\n",
    "\n",
    "The data sets column description is somthing like this:\n",
    "\n",
    "* **id:** The unique identifier from Hacker News for the post\n",
    "* **title:** The title of the post\n",
    "* **url:** The URL that the posts links to, if it the post has a URL\n",
    "* **num_points:** The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "* **num_comments:** The number of comments that were made on the post\n",
    "* **author:** The username of the person who submitted the post\n",
    "* **created_at:** The date and time at which the post was submitted\n",
    "\n",
    "The interest of our analysis is mainly focus in posts with titles that include **Ask HN** or **Show HN** a the begining of the post.\n",
    "\n",
    "* **Ask HN**: Posts to ask questions to the Hacker News community\n",
    "* **Show HN** Posts to show something to Hacker News community\n",
    "\n",
    "Our questions are:\n",
    "\n",
    "* Which of both of the two types of posts receive more comments on average?\n",
    "* Do posts created on certain time receive more comments on average?\n",
    "\n",
    "Let's begin:\n",
    "\n",
    "First we will imported the libraries that we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n",
      "['10176903', 'Toyota Establishes Research Centers with MIT and Stanford for AI Research', 'http://newsroom.toyota.co.jp/en/detail/9233109/', '4', '0', 'tim_sw', '9/6/2015 5:50']\n"
     ]
    }
   ],
   "source": [
    "#Dataset to List of lists\n",
    "file = open('C:/Users/david/Desktop/Autodidacta/Datasets/HN_posts_year_to_Sep_26_2016.csv', encoding=\"utf8\")\n",
    "read_file = reader(file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "#Function for data set visualization\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(row))\n",
    "\n",
    "#Data Set Columns\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "\n",
    "#First five rows and number of columns\n",
    "explore_data(hn, 0, 5, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are all set with our dataset, let's make a filter. As we said we only need the posts that begin with **Ask HN** or **Show HN**. So we need to test the name of the posts and separate them in sub lists with this criteria in account. So we will make use of the stirng method **startswith** for this. The method evaluates a string to see if it starts with a given substring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "\n",
      "\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "\n",
      "\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "\n",
      "\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "\n",
      "\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "\n",
      "\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "\n",
      "\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "\n",
      "\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "\n",
      "\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "\n",
      "\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#Post Filtering\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "#Post quantity in each category\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "\n",
    "#First posts\n",
    "explore_data(ask_posts, 0, 5)\n",
    "explore_data(show_posts, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we filtered the posts, let's answer our first question:\n",
    "\n",
    "Which of the two types of posts receives more comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ask comments: 10.393478498741656\n",
      "Average show comments: 4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "#Get total number of comments in ask posts\n",
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    comments = int(post[4])\n",
    "    total_ask_comments += comments\n",
    "#Get the average number of comments for ask posts\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(\"Average ask comments: {}\".format(avg_ask_comments))\n",
    "\n",
    "#Get total number of comments in show posts\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    comments = int(post[4])\n",
    "    total_show_comments += comments\n",
    "#Get the average number of comments for show posts\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(\"Average show comments: {}\".format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this analysis we have found that the Ask HN posts are the ones with more comments, and it does make sense, because if you think about it, this posts are the ones that are asking to the community about something, and when you get asked something you feel that it needs to be answered. On the other side the Show HN posts are the ones that are for just showing something to the community, the people that comments this, does it because they voluntarily wanted to say something to the person that is showing something in the post. So it makes sense that the average number of comments for Ask HN is approximately 10 and for Show HN approximately 5.\n",
    "\n",
    "Since ask posts are the ones that get more comments, we will focus our analysis in this kind of posts.\n",
    "\n",
    "Now we will determine if ask posts created in certain time are more likely to get comments. For this we will:\n",
    "\n",
    "* Calculate the amount of ask posts created in each hour of the day and the amount of received comments.\n",
    "\n",
    "* Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "So let's do it!\n",
    "\n",
    "For this we will use the datetime module that we imported at the beginning of this project to parse the dates that are given to us as a string into datetiem objects so we can make operations with these.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of lists that contain the date  and number of comments\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    creation_date = post[6]\n",
    "    comments = int(post[4])   \n",
    "    result_list.append([creation_date, comments])\n",
    "\n",
    "#Create 2 dictionaries\n",
    "counts_by_hour = {} #frequency table for number of posts per hour of day\n",
    "comments_by_hour = {} #Total of comments per hour\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    date = dt.datetime.strptime(date,\"%m/%d/%Y  %H:%M\")\n",
    "    hour = date.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1 \n",
    "        comments_by_hour[hour] += row[1]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have 2 dictionaries that tell us the posts per hour and the total comments per hour, we will use them to calculate the average  number of comments for posts created during each hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 11.137546468401487],\n",
       " ['01', 7.407801418439717],\n",
       " ['22', 8.804177545691905],\n",
       " ['21', 8.687258687258687],\n",
       " ['19', 7.163043478260869],\n",
       " ['17', 9.449744463373083],\n",
       " ['15', 28.676470588235293],\n",
       " ['14', 9.692007797270955],\n",
       " ['13', 16.31756756756757],\n",
       " ['11', 8.96474358974359],\n",
       " ['10', 10.684397163120567],\n",
       " ['09', 6.653153153153153],\n",
       " ['07', 7.013274336283186],\n",
       " ['03', 7.948339483394834],\n",
       " ['23', 6.696793002915452],\n",
       " ['20', 8.749019607843136],\n",
       " ['16', 7.713298791018998],\n",
       " ['08', 9.190661478599221],\n",
       " ['00', 7.5647840531561465],\n",
       " ['18', 7.94299674267101],\n",
       " ['12', 12.380116959064328],\n",
       " ['04', 9.7119341563786],\n",
       " ['06', 6.782051282051282],\n",
       " ['05', 8.794258373205741]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in counts_by_hour:\n",
    "    average = comments_by_hour[hour]/counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, average])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the average number of comments for posts created during each hour of the day, let's sort it to have a clear view of the information to analize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[:5]:\n",
    "    avg = row[0]\n",
    "    hour = row[1]\n",
    "    hour = dt.datetime.strptime(hour, \"%H\")\n",
    "    hour = hour.strftime(\"%H:%M\")\n",
    "    template = \"{0}: {1:.2f} average comments per post\"\n",
    "    print(template.format(hour, avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis we can determine that the 3 pm  or 15:00 in 24-hour format (the time zone is Eastern Time in the US), is the hour you are more likely to get the most comments, so you should post at this hour your Ask HN posts if you want more people commenting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
